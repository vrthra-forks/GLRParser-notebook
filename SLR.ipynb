{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import copy\nimport time",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "class LRParser:\n    def __init__(self, grammar, terminals, non_terminals, start, dot):\n        self.grammar = grammar\n        self.terminals = terminals\n        self.non_terminals = non_terminals\n        self.start = start\n        self.dot = dot\n        \n        self.first_table = {}\n        self.follow_table = {}\n        self.in_progress = set()     # to avoid left recursive when calculating first\n        self.calculateFirstTable()\n        self.calculateFollowTable()\n        \n        self.augmented_rules = []    # format of rule: [rhs, [<lhs symbol>]\n        self.state_map = {}          # store rules of a state (format: state_count:[[rule1], [rule2], ...])\n        self.state_dict = {}         # store which state go to which state\n        self.state_count = 0\n        self.initialAugmentation()\n        self.generateStates()\n\n        self.parse_table = []\n        self.createParseTable()\n\n    \n    def shift(self, current_node, next_state, symbol):\n        pass\n\n\n    def reduce(self, current_node, rule):\n        pass\n\n    \n    def initialAugmentation(self):\n        for key in grammar.keys():\n            lhs, rhs = grammar[key]\n            new_rhs = [self.dot]\n            for elem in rhs:\n                new_rhs.append(elem)\n            self.augmented_rules.append([lhs, new_rhs])\n\n    def generateStates(self):\n        \n        # generate the first state I_0\n        first_state = []\n        for rule in self.augmented_rules:\n            if rule[0] == self.start:\n                first_state.append(rule)\n        closure_rules = self.findClosure(first_state)\n        self.state_dict[0] = closure_rules\n\n        # generate states until no more state is able to be generated\n        prev_len = -1\n        state_completed_GOTO = []\n        while prev_len != len(self.state_dict):\n            prev_len = len(self.state_dict)\n\n            keys = list(self.state_dict.keys())\n            for state in keys:\n                if state not in state_completed_GOTO:\n                    self.computeGOTO(state)\n                    state_completed_GOTO.append(state)\n\n    \n    def computeGOTO(self, state):\n        generate_new_state_for = []\n        for rule in self.state_dict[state]:\n            # if the rule ends with dot (can't shift anymore) => skip\n            if rule[1][-1] == self.dot:\n                continue\n\n            dot_ind = rule[1].index(self.dot)\n            next_sym = rule[1][dot_ind+1]\n\n            if next_sym not in generate_new_state_for:\n                generate_new_state_for.append(next_sym)\n\n        for sym in generate_new_state_for:\n            self.GOTO(state, sym)\n\n    \n    def GOTO(self, state, sym):\n        new_state = []\n        for rule in self.state_dict[state]:\n            # if the rule ends with dot (can't shift anymore) => skip\n            if rule[1][-1] == self.dot:\n                continue\n\n            dot_ind = rule[1].index(self.dot)\n            next_sym = rule[1][dot_ind+1]\n\n            # shift operation from the previous state of rule on that\n            if next_sym == sym:\n                # swap dot with next_sym\n                shifted_rule = copy.deepcopy(rule)\n                shifted_rule[1][dot_ind] = shifted_rule[1][dot_ind + 1]\n                shifted_rule[1][dot_ind + 1] = self.dot\n                new_state.append(shifted_rule)\n\n        closure_rules = self.findClosure(new_state)\n\n        # check if state exist\n        state_exists = -1\n        for state_num in self.state_dict:\n            if self.state_dict[state_num] == new_state:\n                state_exists = state_num\n                break\n     \n        # stateMap is a mapping of GOTO with\n        # its output states\n        if state_exists == -1:\n            self.state_count += 1\n            self.state_dict[self.state_count] = closure_rules\n            self.state_map[(state, sym)] = self.state_count\n        else:\n            self.state_map[(state, sym)] = state_exists\n            \n\n    def findClosure(self, closure_rules):\n        # generate closure for the rules in new_state\n        # generate until can't generate anymore\n        prev_len = -1\n        while prev_len != len(closure_rules):\n            prev_len = len(closure_rules)\n            for rule in closure_rules:\n                if rule[1][-1] == self.dot:\n                    continue\n                    \n                dot_ind = rule[1].index(self.dot)\n                next_sym = rule[1][dot_ind+1]\n    \n                # if next_sym is non_terminal then continue adding rule with that nonterminals as lhs\n                if next_sym in self.non_terminals:\n                    for augmented_rule in self.augmented_rules:\n                        if augmented_rule[0] == next_sym and augmented_rule not in closure_rules:\n                            closure_rules.append(augmented_rule)\n        return closure_rules\n\n        \n    def calculateFirstTable(self):\n        for key in grammar.keys():\n            rule = grammar[key]\n            lhs, rhs = rule\n\n            if lhs not in self.first_table:\n                self.first_table[lhs] = list(elem for elem in self.first(rule))\n            else:\n                res = self.first(rule)\n                for elem in res:\n                    if elem not in self.first_table[lhs]:\n                        self.first_table[lhs].append(elem)\n\n    \n    def calculateFollowTable(self):\n        for nt in self.non_terminals:\n            self.follow_table[nt] = self.follow(nt)\n\n    \n    def first(self, rule):\n        lhs, rhs = rule\n        \n        if lhs in self.in_progress:\n            return []  # prevent infinite recursion\n        \n        # mark this non-terminal as being processed\n        self.in_progress.add(lhs)\n        \n        # rule for terminals\n        if rhs[0] in terminals:\n            return [rhs[0]]\n            \n        # rule for epsilon\n        elif rhs[0] == \"#\":\n            return [\"#\"]\n            \n        # rule for non-terminal\n        else:\n            res = []\n            for key in grammar.keys():\n                if rhs[0] == grammar[key][0]:\n                    for elem in self.first(grammar[key]):\n                        res.append(elem) \n\n            if \"#\" in res:\n                res.remove(\"#\")\n                \n            self.in_progress.remove(lhs)  # finished processing this non-terminal\n            return res\n\n    \n    def follow(self, nt, visited=None):\n        if visited is None:\n            visited = set()\n    \n        if nt in visited:\n            return []\n\n        visited.add(nt)\n        res = set()\n\n        # for start symbol return $\n        if nt == self.start:\n            res.add(\"$\")\n\n        for key in grammar.keys():\n            lhs, rhs = grammar[key]\n            \n            for i, symbol in enumerate(rhs):\n                if symbol == nt:\n                    rhs = rhs[i + 1:]\n\n                    # rule 2: there is a symbol after nt\n                    if len(rhs) != 0:\n                        # if the symbol after nt is also a non-terminal:\n                        #   - calculate its first (remove epsilon) and add to res\n                        #   - if its first contain epsilon, then continue checking the next symbol\n                        # else the symbol after nt is a terminal:\n                        #   - then add it to res\n                        for sym in rhs:\n                            if sym in self.terminals:\n                                res.add(sym)\n                                break\n                            elif sym in self.first_table:\n                                first_sym = self.first_table[sym]\n                                res.update(set(first_sym) - {\"#\"})\n    \n                                if \"#\" in first_sym:\n                                    res.remove(\"#\")\n                                else:\n                                    break\n\n                    # rule 3: there is no symbol after nt -> FOLLOW(lhs) ⊆ FOLLOW(nt)\n                    if len(rhs) == 0:  \n                        if lhs != nt:\n                            res.update(self.follow(lhs, visited))\n                            \n        visited.remove(nt)\n        return list(res)\n\n    def createParseTable(self):\n        rows = list(self.state_dict.keys())\n        cols = self.terminals + [\"$\"] + self.non_terminals\n\n        # create empty table\n        temp_row = []\n        for i in range(len(cols)):\n            temp_row.append([])\n        for i in range(len(rows)):\n            self.parse_table.append(copy.deepcopy(temp_row))\n\n        # add shift and goto entries to table\n        for entry in self.state_map.keys():\n            state = entry[0]\n            sym = entry[1]\n\n            row_ind = rows.index(state)\n            col_ind = cols.index(sym)\n\n            if sym in self.terminals:\n                self.parse_table[row_ind][col_ind].append(f\"S{self.state_map[entry]}\")\n            elif sym in self.non_terminals:\n                self.parse_table[row_ind][col_ind].append(f\"G{self.state_map[entry]}\")\n\n        # add reduce to table\n        for state in self.state_dict.keys():\n            for rule in self.state_dict[state]:\n                # if the rule is a handle -> add reduce correspondingly\n                if rule[1][-1] == self.dot:\n                    copy_rhs = copy.deepcopy(rule[1])\n                    copy_rhs.remove(self.dot)\n\n                    # add entry R_rule_num (Reduce -> rule_num) to entry (state, follow(rhs)) in parse table\n                    for rule_num in self.grammar.keys():\n                        if grammar[rule_num][0] == rule[0] and grammar[rule_num][1] == copy_rhs:\n                            for follow in self.follow_table[rule[0]]:\n                                row_ind = rows.index(state)\n                                col_ind = cols.index(follow)\n                                if rule_num == 0:\n                                    self.parse_table[row_ind][col_ind].append(\"Accept\")\n                                else:\n                                    self.parse_table[row_ind][col_ind].append(f\"R{rule_num}\")\n\n    \t# printing table\n        print(\"\\nParsing table:\\n\")\n        frmt = \"{:>8}\" * len(cols)\n        print(\" \", frmt.format(*cols), \"\\n\")\n        ptr = 0\n        j = 0\n        for y in self.parse_table:\n            # frmt1 = \"{:>8}\"\n            print(f\"{{:>3}}\".format('I'+str(j)), end=\"\")\n            for e in y:\n                print(f\"{{:>8}}\".format(\"/\".join(e)), end=\"\")\n            print()\n            j += 1\n            \n        file = open(\"rules/parse_tables/parsetable1.csv\", \"w\")\n        file.write(\"state,\"+\",\".join(cols)+\"\\n\")\n        j = 0\n        for y in self.parse_table:\n            line = \"\"\n            line += f\"I{j}\"\n            for e in y:\n                line += \",\" + \"/\".join(e)\n            file.write(line + \"\\n\")\n            j += 1\n        file.close()\n        \n\n    def printResultAndGoto(self):\n        print(\"\\nStates Generated: \\n\")\n        for st in self.state_dict:\n            print(f\"State = I{st}\")\n            self.printResult(self.state_dict[st])\n            print()# print goto states\n        print(\"\\nStates Generated: \\n\")\n        for st in self.state_dict:\n            print(f\"State = I{st}\")\n            self.printResult(self.state_dict[st])\n            print()\n\n        print(\"Result of GOTO computation:\\n\")\n        self.printAllGOTO(self.state_map)\n\n    \n\n    def printResult(self, rules):\n        for rule in rules:\n            print(f\"{rule[0]} ->\"\n                  f\" {' '.join(rule[1])}\")\n\n    def printAllGOTO(self, diction):\n        for itr in diction:\n            print(f\"GOTO ( I{itr[0]} ,\"\n                  f\" {itr[1]} ) = I{self.state_map[itr]}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "class SLRParser(LRParser):\n    def __init__(self, grammar, terminals, non_terminals, start, dot):\n        super().__init__(grammar, terminals, non_terminals, start, dot)\n\n    def parse(self, input_string):\n        # self.printResultAndGoto()\n        rows = list(self.state_dict.keys())\n        cols = self.terminals + [\"$\"] + self.non_terminals\n        \n        ls_input = input_string + [\"$\"]\n        current_char = ls_input[0]\n        ls_output = []\n        stack = [0]\n        while True:\n            # print(ls_input, current_char, stack)\n            # time.sleep(1)\n            if current_char not in cols:\n                return False\n            \n            row_ind = rows.index(stack[-1])\n            col_ind = cols.index(current_char)\n            \n            operation = self.parse_table[row_ind][col_ind]\n            \n            if operation == []:\n                return False\n                \n            else:\n                operation = operation[0] # just get the first operation in conflict cell\n                # print(operation)\n                # reduce operation\n                if operation[0] == \"R\":\n                    rule_num = int(operation[1:])\n                    current_char = self.grammar[rule_num][0]\n                    \n                    # pop stack equal to number of char on rhs of reduce rule\n                    stack_pop_count = len(self.grammar[rule_num][1])\n                    stack = stack[:-stack_pop_count]\n\n                    ls_output.append(rule_num)\n                \n                # goto operation\n                elif operation[0] == \"G\":\n                    stack.append(int(operation[1:]))\n                    current_char = ls_input[0]  \n                    \n                # shift operation\n                elif operation[0] == \"S\":\n                    stack.append(int(operation[1:]))\n                    ls_input.pop(0) \n                    current_char = ls_input[0]      \n\n                # accept reached\n                elif operation == \"Accept\":\n                    return True\n\n    \n# Example 1 Grammar and Tables\ngrammar = {\n    0: (\"E'\", [\"E\"]),                # Rule 0: E'→ E\n    1: (\"E\", [\"E\", \"+\", \"T\"]),       # Rule 1: E → E + T\n    2: (\"E\", [\"T\"]),                 # Rule 2: E → T\n    3: (\"T\", [\"T\", \"*\", \"F\"]),       # Rule 3: T → T * F\n    4: (\"T\", [\"F\"]),                 # Rule 4: T → F\n    5: (\"F\", [\"(\", \"E\", \")\"]),       # Rule 5: F → ( E )\n    6: (\"F\", [\"a\"]),                 # Rule 6: F → a\n    \n}\n\nterminals = [\"a\", \"+\", \"*\",\"(\", \")\"]\nnon_terminals = [\"E'\", \"E\", \"T\", \"F\"]\nstart = \"E'\"\ndot = '·'\n\n# Test the Parser\nparser = SLRParser(grammar, terminals, non_terminals, start, dot)\ninput_string = list(\"a*a+a*a+a\")\nres = parser.parse(input_string)\nif res == False:\n    print(f\"Input not accepted - {\"\".join(input_string)}\")\nelse:\n    print(f\"Input accepted - {\"\".join(input_string)}\")\n\n\n\n# # Example 2 Grammar and Tables\n# grammar = {\n#     0: (\"S'\", [\"S\"]),\n#     1: (\"S\", [\"L\", \"=\", \"R\"]),    # Rule 1: S → L = R\n#     2: (\"S\", [\"R\"]),              # Rule 2: S → R\n#     3: (\"L\", [\"*\", \"R\"]),         # Rule 3: L → * R\n#     4: (\"L\", [\"a\"]),              # Rule 4: L → a\n#     5: (\"R\", [\"L\"]),              # Rule 5: R → L\n# }\n\n# terminals = [\"a\", \"=\", \"*\"]\n# non_terminals = [\"S'\", \"S\", \"L\", \"R\"]\n# start = \"S'\"\n# dot = '·'\n\n# # Test the Parser\n# parser = SLRParser(grammar, terminals, non_terminals, start, dot)\n# # input_string = list(\"a=a\")\n# # parser.parse(input_string)\n\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nParsing table:\n\n         a       +       *       (       )       $      E'       E       T       F \n\n I0      S5                      S4                              G1      G2      G3\n I1              S6                          Accept                                \n I2              R2      S7              R2      R2                                \n I3              R4      R4              R4      R4                                \n I4      S5                      S4                              G8      G2      G3\n I5              R6      R6              R6      R6                                \n I6      S5                      S4                                      G9      G3\n I7      S5                      S4                                             G10\n I8              S6                     S11                                        \n I9              R1      S7              R1      R1                                \nI10              R3      R3              R3      R3                                \nI11              R5      R5              R5      R5                                \nInput accepted - a*a+a*a+a\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "# 2. Generator",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from collections import deque\n\nclass GrammarExpander:\n    def __init__(self, grammar, terminals, start):\n        self.grammar = grammar\n        self.terminals = terminals\n        self.start_symbol = start\n\n    def is_fully_expanded(self, symbols):\n        \"\"\"Check if all the symbols in the list are terminals.\"\"\"\n        return all(symbol in self.terminals for symbol in symbols)\n\n    def get_productions_for(self, symbol):\n        return [prod for lhs, prod in self.grammar.values() if lhs == symbol]\n\n    def expand_grammar(self, max_strings, max_depth):\n        queue = deque([([self.start_symbol], 0)])  # (current list of symbols, current depth)\n        seen_strings = set()  # To avoid duplicates\n        results = set()  # Store unique results (only fully terminal strings)\n        \n        while queue and len(results) < max_strings:\n            current_string, depth = queue.popleft()\n            \n            # If the current string is fully expanded, store it as a result\n            if self.is_fully_expanded(current_string):\n                result_string = ''.join(current_string)  # Convert list of symbols back to string\n                if result_string not in results:\n                    results.add(result_string)\n            elif depth < max_depth:\n                # Find the first non-terminal to expand\n                for i, symbol in enumerate(current_string):\n                    if symbol not in self.terminals:\n                        # Get productions for this non-terminal\n                        productions = self.get_productions_for(symbol)\n                        for production in productions:\n                            # Replace part of the list with the production\n                            new_string = current_string[:i] + production + current_string[i+1:]\n                            if tuple(new_string) not in seen_strings:\n                                queue.append((new_string, depth + 1))\n                                seen_strings.add(tuple(new_string))  # Store the tuple to avoid duplicate lists\n                        break  # Only expand one non-terminal at a time\n        \n        return list(results)\n\n\n# Example 1 Grammar and Tables\ngrammar = {\n    0: (\"E'\", [\"E\"]),                # Rule 0: E'→ E\n    1: (\"E\", [\"E\", \"+\", \"T\"]),       # Rule 1: E → E + T\n    2: (\"E\", [\"T\"]),                 # Rule 2: E → T\n    3: (\"T\", [\"T\", \"*\", \"F\"]),       # Rule 3: T → T * F\n    4: (\"T\", [\"F\"]),                 # Rule 4: T → F\n    5: (\"F\", [\"(\", \"E\", \")\"]),       # Rule 5: F → ( E )\n    6: (\"F\", [\"a\"]),                 # Rule 6: F → a\n    \n}\n\nterminals = [\"a\", \"+\", \"*\",\"(\", \")\"]\nnon_terminals = [\"E'\", \"E\", \"T\", \"F\"]\nstart = \"E'\"\ndot = '·'\n\nparser = SLRParser(grammar, terminals, non_terminals, start, dot)\n\nexpander = GrammarExpander(grammar, terminals, start)\n\nnum_string = 10000\nvalid_strings = expander.expand_grammar(max_strings=num_string, max_depth=1000)\n\n# Test the parser\nls_false = []\nfor i, s in enumerate(valid_strings):\n    # res = parser.parse(list(s[:int(len(s)/2)]))\n    res = parser.parse(list(s))\n    if res == False:\n        ls_false.append(s)\n\nprint(f\"Accuracy: {round((num_string - len(ls_false))/num_string,5)*100}%\")\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nParsing table:\n\n         a       +       *       (       )       $      E'       E       T       F \n\n I0      S5                      S4                              G1      G2      G3\n I1              S6                          Accept                                \n I2              R2      S7              R2      R2                                \n I3              R4      R4              R4      R4                                \n I4      S5                      S4                              G8      G2      G3\n I5              R6      R6              R6      R6                                \n I6      S5                      S4                                      G9      G3\n I7      S5                      S4                                             G10\n I8              S6                     S11                                        \n I9              R1      S7              R1      R1                                \nI10              R3      R3              R3      R3                                \nI11              R5      R5              R5      R5                                \nAccuracy: 100.0%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "for e in ls_false:\n    print(e)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import random\n\nclass InvalidStringGenerator:\n    def __init__(self, terminals, non_terminals):\n        self.terminals = terminals\n        self.non_terminals = non_terminals\n        self.invalid_symbols = ['x', 'y', 'z', '1', '2', '3', '@', '#', '$']  # Invalid symbols\n    \n    def generate_invalid_string(self, valid_string):\n        \"\"\" Randomly pick one of the corruption strategies \"\"\"\n        strategies = [\n            self._symbol_corruption,\n            self._random_string,\n            self._rule_mutation,\n            self._non_terminal_insertion\n        ]\n        strategy = random.choice(strategies)\n        return strategy(valid_string)\n    \n    def _symbol_corruption(self, valid_string, corruption_rate=0.3):\n        \"\"\" Replace, insert, or delete terminals in a valid string \"\"\"\n        corrupted_string = []\n        all_symbols = self.terminals + self.invalid_symbols\n        \n        for char in valid_string:\n            if random.random() < corruption_rate:  # Decide to corrupt this character\n                choice = random.choice(all_symbols)  # Randomly replace it with a symbol\n                corrupted_string.append(choice)\n            else:\n                corrupted_string.append(char)  # Keep the original character\n        \n        if random.random() < corruption_rate:\n            # Randomly insert an extra symbol\n            insert_index = random.randint(0, len(corrupted_string))\n            extra_symbol = random.choice(self.invalid_symbols)\n            corrupted_string.insert(insert_index, extra_symbol)\n        \n        return ''.join(corrupted_string)\n    \n    def _random_string(self, valid_string, min_length=3, max_length=10):\n        \"\"\" Generate a completely random string \"\"\"\n        all_symbols = self.terminals + self.invalid_symbols + self.non_terminals\n        length = random.randint(min_length, max_length)\n        return ''.join(random.choice(all_symbols) for _ in range(length))\n    \n    def _rule_mutation(self, valid_string, mutation_rate=0.3):\n        \"\"\" Mutate a valid string by violating grammar production rules \"\"\"\n        mutated_string = []\n        for char in valid_string:\n            if char in self.terminals and random.random() < mutation_rate:\n                new_symbol = random.choice(self.invalid_symbols)\n                mutated_string.append(new_symbol)\n            else:\n                mutated_string.append(char)\n        \n        return ''.join(mutated_string)\n    \n    def _non_terminal_insertion(self, valid_string, insertion_rate=0.3):\n        \"\"\" Insert non-terminals into an otherwise valid string \"\"\"\n        result = []\n        for char in valid_string:\n            if random.random() < insertion_rate:\n                result.append(random.choice(self.non_terminals))  # Insert a non-terminal\n            result.append(char)\n        return ''.join(result)\n\n\ngenerator = InvalidStringGenerator(terminals, non_terminals)\n\n# Generate 10 completely invalid strings\nnum_string = 10\ninvalid_strings = [generator.generate_invalid_string(random.choice(valid_strings)) for _ in range(num_string)]\n\n# Test the parser\nls_true = []\nfor i, s in enumerate(invalid_strings):\n    print(s)\n    res = parser.parse(list(s))\n    if res == True:\n        ls_true.append(s)\n\nprint(f\"Accuracy: {round((num_string - len(ls_true))/num_string,5)*100}%\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "((Fa)E)+a*(a+a)\na*1a+(a*a@2*a*a\n$#(a*az+((a)*a)\nE12+1\n((((y$1z#z)@\ny+a*a*(a*(+1))1\n@(((3)))*a+a)\nTaT*a*a+aT*FaT+E(a)\na+a*Ta*a+a*a*E'a\n2ax+@#((@*a))\nAccuracy: 100.0%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}